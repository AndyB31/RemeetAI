{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b7e3615",
   "metadata": {},
   "source": [
    "# Code inspired from article https://towardsdatascience.com/text-summarization-with-nlp-textrank-vs-seq2seq-vs-bart-474943efeb09  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b456c9ba",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eea3043",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TFT5Tokenizer' from 'transformers' (C:\\Users\\loren\\.virtualenvs\\text_summarization-RZoufpZG\\lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m## for bart\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#import transformers\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m##for generating sentence after textrank \u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TFT5Tokenizer, TFT5ForConditionalGeneration\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'TFT5Tokenizer' from 'transformers' (C:\\Users\\loren\\.virtualenvs\\text_summarization-RZoufpZG\\lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "## for data\n",
    "import datasets \n",
    "import pandas as pd \n",
    "import numpy \n",
    "## for plotting\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "## for preprocessing\n",
    "import re\n",
    "import nltk \n",
    "import contractions \n",
    "import os\n",
    "## for textrank\n",
    "import gensim #summarize was deleted in later version due to poor performance, never in use in Production, not maintained\n",
    "import pytextrank\n",
    "import spacy\n",
    "## for evaluation\n",
    "import rouge  \n",
    "import difflib\n",
    "## for seq2seq\n",
    "from tensorflow.keras import callbacks, models, layers, preprocessing as kprocessing \n",
    "## for bart\n",
    "#import transformers\n",
    "##for generating sentence after textrank \n",
    "import openai\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea0e7a4",
   "metadata": {},
   "source": [
    "# import dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee4f0edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cnn_dailymail (C:/Users/loren/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df30bc6c43e240d4a615af97895d1b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## load the full dataset of 300k articles\n",
    "dataset = datasets.load_dataset(\"cnn_dailymail\", '3.0.0')\n",
    "lst_dics = [dic for dic in dataset[\"train\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f498b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LONDON, England (Reuters) -- Harry Potter star...</td>\n",
       "      <td>Harry Potter star Daniel Radcliffe gets £20M f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Editor's note: In our Behind the Scenes series...</td>\n",
       "      <td>Mentally ill inmates in Miami are housed on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MINNEAPOLIS, Minnesota (CNN) -- Drivers who we...</td>\n",
       "      <td>NEW: \"I thought I was going to die,\" driver sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WASHINGTON (CNN) -- Doctors removed five small...</td>\n",
       "      <td>Five small polyps found during procedure; \"non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(CNN)  -- The National Football League has ind...</td>\n",
       "      <td>NEW: NFL chief, Atlanta Falcons owner critical...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   \n",
       "0  LONDON, England (Reuters) -- Harry Potter star...  \\\n",
       "1  Editor's note: In our Behind the Scenes series...   \n",
       "2  MINNEAPOLIS, Minnesota (CNN) -- Drivers who we...   \n",
       "3  WASHINGTON (CNN) -- Doctors removed five small...   \n",
       "4  (CNN)  -- The National Football League has ind...   \n",
       "\n",
       "                                                   y  \n",
       "0  Harry Potter star Daniel Radcliffe gets £20M f...  \n",
       "1  Mentally ill inmates in Miami are housed on th...  \n",
       "2  NEW: \"I thought I was going to die,\" driver sa...  \n",
       "3  Five small polyps found during procedure; \"non...  \n",
       "4  NEW: NFL chief, Atlanta Falcons owner critical...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## keep the first N articles if you want to keep it lite \n",
    "dtf = pd.DataFrame(lst_dics).rename(columns={\"article\":\"text\", \n",
    "      \"highlights\":\"y\"})[[\"text\",\"y\"]].head(20000)\n",
    "dtf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef00cbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Full text ---\n",
      "LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don't think I'll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he'll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I'll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe's earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say 'kid star goes off the rails,'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter's latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer's \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he's legally an adult: \"I just think I'm going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.\n",
      "--- Summary ---\n",
      "Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\n",
      "Young actor says he has no plans to fritter his cash away .\n",
      "Radcliffe's earnings from first five Potter films have been held in trust fund .\n"
     ]
    }
   ],
   "source": [
    "#check one example \n",
    "i = 0\n",
    "print(\"--- Full text ---\")\n",
    "print(dtf[\"text\"][i])\n",
    "print(\"--- Summary ---\")\n",
    "print(dtf[\"y\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf61180a",
   "metadata": {},
   "source": [
    "# create train/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db1703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf_train = dtf.iloc[i+1:]\n",
    "dtf_test = dtf.iloc[:i+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c9d961",
   "metadata": {},
   "source": [
    "# TextRank algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f8f2260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/12.8 MB 1.7 MB/s eta 0:00:08\n",
      "     ---------------------------------------- 0.1/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     ---------------------------------------- 0.1/12.8 MB 1.0 MB/s eta 0:00:13\n",
      "     --------------------------------------- 0.1/12.8 MB 944.1 kB/s eta 0:00:14\n",
      "      --------------------------------------- 0.2/12.8 MB 1.0 MB/s eta 0:00:13\n",
      "      --------------------------------------- 0.2/12.8 MB 1.0 MB/s eta 0:00:13\n",
      "      --------------------------------------- 0.3/12.8 MB 1.0 MB/s eta 0:00:13\n",
      "     - -------------------------------------- 0.3/12.8 MB 1.1 MB/s eta 0:00:12\n",
      "     - -------------------------------------- 0.4/12.8 MB 1.1 MB/s eta 0:00:12\n",
      "     - -------------------------------------- 0.4/12.8 MB 1.1 MB/s eta 0:00:12\n",
      "     - -------------------------------------- 0.5/12.8 MB 1.2 MB/s eta 0:00:11\n",
      "     - -------------------------------------- 0.5/12.8 MB 1.2 MB/s eta 0:00:11\n",
      "     - -------------------------------------- 0.6/12.8 MB 1.2 MB/s eta 0:00:11\n",
      "     - -------------------------------------- 0.6/12.8 MB 1.2 MB/s eta 0:00:10\n",
      "     -- ------------------------------------- 0.7/12.8 MB 1.2 MB/s eta 0:00:10\n",
      "     -- ------------------------------------- 0.7/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     -- ------------------------------------- 0.8/12.8 MB 1.2 MB/s eta 0:00:10\n",
      "     -- ------------------------------------- 0.8/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     -- ------------------------------------- 0.9/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     --- ------------------------------------ 1.0/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     --- ------------------------------------ 1.0/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     --- ------------------------------------ 1.1/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     --- ------------------------------------ 1.1/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     --- ------------------------------------ 1.1/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     --- ------------------------------------ 1.1/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     --- ------------------------------------ 1.2/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     --- ------------------------------------ 1.2/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 1.2 MB/s eta 0:00:10\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     ---- ----------------------------------- 1.5/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 1.5/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     ----- ---------------------------------- 1.7/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     ----- ---------------------------------- 1.9/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     ------ --------------------------------- 2.0/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     ------ --------------------------------- 2.1/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     ------ --------------------------------- 2.2/12.8 MB 1.5 MB/s eta 0:00:08\n",
      "     ------- -------------------------------- 2.2/12.8 MB 1.5 MB/s eta 0:00:08\n",
      "     ------- -------------------------------- 2.3/12.8 MB 1.5 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 2.4/12.8 MB 1.5 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 2.5/12.8 MB 1.6 MB/s eta 0:00:07\n",
      "     -------- ------------------------------- 2.6/12.8 MB 1.6 MB/s eta 0:00:07\n",
      "     -------- ------------------------------- 2.7/12.8 MB 1.6 MB/s eta 0:00:07\n",
      "     -------- ------------------------------- 2.8/12.8 MB 1.6 MB/s eta 0:00:07\n",
      "     --------- ------------------------------ 2.9/12.8 MB 1.7 MB/s eta 0:00:06\n",
      "     --------- ------------------------------ 3.0/12.8 MB 1.7 MB/s eta 0:00:06\n",
      "     --------- ------------------------------ 3.1/12.8 MB 1.7 MB/s eta 0:00:06\n",
      "     ---------- ----------------------------- 3.2/12.8 MB 1.7 MB/s eta 0:00:06\n",
      "     ---------- ----------------------------- 3.3/12.8 MB 1.7 MB/s eta 0:00:06\n",
      "     ---------- ----------------------------- 3.5/12.8 MB 1.8 MB/s eta 0:00:06\n",
      "     ----------- ---------------------------- 3.6/12.8 MB 1.8 MB/s eta 0:00:06\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 1.8 MB/s eta 0:00:05\n",
      "     ----------- ---------------------------- 3.8/12.8 MB 1.9 MB/s eta 0:00:05\n",
      "     ------------ --------------------------- 3.9/12.8 MB 1.9 MB/s eta 0:00:05\n",
      "     ------------ --------------------------- 4.1/12.8 MB 1.9 MB/s eta 0:00:05\n",
      "     ------------ --------------------------- 4.2/12.8 MB 1.9 MB/s eta 0:00:05\n",
      "     ------------- -------------------------- 4.3/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     ------------- -------------------------- 4.4/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 4.6/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 4.7/12.8 MB 2.0 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 4.9/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 5.0/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 5.1/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 5.3/12.8 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 5.6/12.8 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 5.7/12.8 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 5.9/12.8 MB 2.3 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 6.0/12.8 MB 2.3 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 6.3/12.8 MB 2.3 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 6.4/12.8 MB 2.4 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 6.6/12.8 MB 2.4 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 6.8/12.8 MB 2.4 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.0/12.8 MB 2.5 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 2.5 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 7.4/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.9/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.1/12.8 MB 2.7 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.3/12.8 MB 2.7 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.5/12.8 MB 2.8 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.8/12.8 MB 2.8 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 9.0/12.8 MB 2.9 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 9.3/12.8 MB 2.9 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 3.0 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 9.8/12.8 MB 3.0 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.1/12.8 MB 3.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.4/12.8 MB 3.2 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.6/12.8 MB 3.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 3.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 3.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.7/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 11.9/12.8 MB 4.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 4.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.29.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.7.2)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\loren\\.virtualenvs\\text_summarization-rzoufpzg\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2258a428",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytextrank.base.BaseTextRankFactory at 0x23d986c2140>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Add PyTextRank to the spaCy pipeline\n",
    "nlp.add_pipe(\"textrank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7447ae8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "GENSIM OUTDATED VERSION\n",
    "Summarizes corpus with TextRank.\n",
    ":parameter    \n",
    "    :param corpus: str or list - dtf[\"text\"]    \n",
    "    :param ratio: length of the summary (ex. 20% of the text)\n",
    ":return    \n",
    "    list of summaries\n",
    "'''\n",
    "def textrank(corpus, ratio=0.2):    \n",
    "    if type(corpus) is str:        \n",
    "        corpus = [corpus]    \n",
    "    lst_summaries = [gensim.summarization.summarize(txt,  \n",
    "                     ratio=ratio) for txt in corpus]    \n",
    "    return lst_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5665631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply textrank algorithm to corpus with a ratio parameter\n",
    "def ptrank(corpus, ratio=0.2):\n",
    "    if type(corpus) is str:\n",
    "        corpus = [corpus]\n",
    "    lst_phrases = []\n",
    "    for txt in corpus:\n",
    "        # Parse the document with spaCy\n",
    "        doc = nlp(txt)\n",
    "        # Extract the top-ranked phrases from the document\n",
    "        phrases = []\n",
    "        for phrase in doc._.phrases:\n",
    "            phrases.append((phrase.text, phrase.rank))\n",
    "        # Sort the phrases by rank\n",
    "        phrases = sorted(phrases, key=lambda x: x[1], reverse=True)\n",
    "        # Limit the number of phrases based on the ratio\n",
    "        limit = int(len(phrases) * ratio)\n",
    "        # Append only the top phrases to the lst_phrases list\n",
    "        lst_phrases.append(phrases[:limit])\n",
    "    return lst_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59da5cfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('last month', 0.09028334388935466),\n",
       " ('Harry Potter', 0.08470743888327945),\n",
       " ('Harry Potter star Daniel Radcliffe', 0.08451745312035847),\n",
       " ('Potter', 0.07130478022388759),\n",
       " ('celebrity parties', 0.06502224902268608),\n",
       " ('fast cars', 0.06323968373052252),\n",
       " ('Part II', 0.06025288049638938),\n",
       " ('author Rudyard Kipling', 0.059676352987717604),\n",
       " ('party', 0.05490785094705813),\n",
       " ('Rudyard Kipling', 0.05388817654532417),\n",
       " ('kid star', 0.05344539230182263),\n",
       " ('drink', 0.051234195299302315),\n",
       " ('the UK box office chart', 0.050236193717111216),\n",
       " ('Reuters', 0.04823424253485198),\n",
       " ('DVDs', 0.04749590035052297),\n",
       " ('Daniel Radcliffe', 0.04741469242892149),\n",
       " ('Phoenix', 0.04683664224799264),\n",
       " ('fair game', 0.04682495302054514),\n",
       " ('release', 0.046285759234409585),\n",
       " ('Australian', 0.04606602314363066),\n",
       " ('Atlantic', 0.044793935362700106),\n",
       " ('UK', 0.04444162895327798),\n",
       " ('the horror film', 0.04431792905585396),\n",
       " ('records', 0.04381254489108988),\n",
       " ('Potters latest »', 0.04372498306327185),\n",
       " ('the first five Potter films', 0.041190299755422946),\n",
       " ('a massive sports car collection', 0.04056647568050417)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to corpus with a ratio of 0.2\n",
    "predicted  = ptrank(corpus=dtf_test[\"text\"], ratio=0.2)\n",
    "predicted [i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7034645",
   "metadata": {},
   "source": [
    "## Result using basic concatenation of top[ratio] words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aca6c96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last month,Harry Potter,Harry Potter star Daniel Radcliffe,Potter,celebrity parties,fast cars,Part II,author Rudyard Kipling,party,Rudyard Kipling,kid star,drink,the UK box office chart,Reuters,DVDs,Daniel Radcliffe,Phoenix,fair game,release,Australian,Atlantic,UK,the horror film,records,Potters latest »,the first five Potter films,a massive sports car collection\n"
     ]
    }
   ],
   "source": [
    "s = \",\".join([str(t[0]) for t in predicted[i]])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70f272",
   "metadata": {},
   "source": [
    "## Result using keyword and OPEN API GPT3 Davinci (billing problem for now, contacted openAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb6a64d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"open_ai_api_key.txt\", \"r\") as f:\n",
    "    openai.api_key = f.read().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4766f868",
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = \",\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a4f6e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format predicted as a partial text\n",
    "input = \"Generate a sentence from the following keywords:\\n\\n\"\n",
    "for keyword, value in predicted[i]:\n",
    "    input += f\"- {keyword}, {value}\\n\"\n",
    "input += \"\\nSentence:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "10faff1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Send a request to the OpenAI API using the text completion feature\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdavinci\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\text_summarization-RZoufpZG\\lib\\site-packages\\openai\\api_resources\\completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32m~\\.virtualenvs\\text_summarization-RZoufpZG\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32m~\\.virtualenvs\\text_summarization-RZoufpZG\\lib\\site-packages\\openai\\api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    211\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    219\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    220\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    221\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    222\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    229\u001b[0m     )\n\u001b[1;32m--> 230\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32m~\\.virtualenvs\\text_summarization-RZoufpZG\\lib\\site-packages\\openai\\api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    617\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    618\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    619\u001b[0m         )\n\u001b[0;32m    620\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    621\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 624\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    630\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    631\u001b[0m     )\n",
      "File \u001b[1;32m~\\.virtualenvs\\text_summarization-RZoufpZG\\lib\\site-packages\\openai\\api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    685\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 687\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    688\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    689\u001b[0m     )\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "# Send a request to the OpenAI API using the text completion feature\n",
    "response = openai.Completion.create(\n",
    "    engine=\"davinci\",\n",
    "    prompt=input,\n",
    "    max_tokens=50,\n",
    "    temperature=0.5,\n",
    "    frequency_penalty=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a91f285",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Print the generated sentence\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "# Print the generated sentence\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bff613",
   "metadata": {},
   "source": [
    "## Same using HuggingFace transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41c0ecb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TFT5Tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load tokenizer and model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mTFT5Tokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt5-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m TFT5ForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt5-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TFT5Tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = TFT5Tokenizer.from_pretrained(\"t5-base\")\n",
    "model = TFT5ForConditionalGeneration.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140821c4",
   "metadata": {},
   "source": [
    "# Evaluate result "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5db5eec",
   "metadata": {},
   "source": [
    "### ROUGE (Recall-Oriented Understudy for Gisting Evaluation) score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2730d24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- ---------\n",
      "absl-py                      1.4.0\n",
      "aiohttp                      3.8.4\n",
      "aiosignal                    1.3.1\n",
      "anyascii                     0.3.2\n",
      "anyio                        3.6.2\n",
      "argon2-cffi                  21.3.0\n",
      "argon2-cffi-bindings         21.2.0\n",
      "arrow                        1.2.3\n",
      "asttokens                    2.2.1\n",
      "astunparse                   1.6.3\n",
      "async-timeout                4.0.2\n",
      "attrs                        23.1.0\n",
      "backcall                     0.2.0\n",
      "beautifulsoup4               4.12.2\n",
      "bleach                       6.0.0\n",
      "blis                         0.7.9\n",
      "cachetools                   5.3.0\n",
      "catalogue                    2.0.8\n",
      "certifi                      2022.12.7\n",
      "cffi                         1.15.1\n",
      "charset-normalizer           3.1.0\n",
      "click                        8.1.3\n",
      "colorama                     0.4.6\n",
      "comm                         0.1.3\n",
      "confection                   0.0.4\n",
      "contourpy                    1.0.7\n",
      "contractions                 0.1.73\n",
      "cycler                       0.11.0\n",
      "cymem                        2.0.7\n",
      "datasets                     2.12.0\n",
      "debugpy                      1.6.7\n",
      "decorator                    5.1.1\n",
      "defusedxml                   0.7.1\n",
      "dill                         0.3.6\n",
      "en-core-web-sm               3.5.0\n",
      "executing                    1.2.0\n",
      "fastjsonschema               2.16.3\n",
      "filelock                     3.12.0\n",
      "flatbuffers                  23.3.3\n",
      "fonttools                    4.39.3\n",
      "fqdn                         1.5.1\n",
      "frozenlist                   1.3.3\n",
      "fsspec                       2023.4.0\n",
      "gast                         0.4.0\n",
      "gensim                       4.3.1\n",
      "google-auth                  2.17.3\n",
      "google-auth-oauthlib         1.0.0\n",
      "google-pasta                 0.2.0\n",
      "graphviz                     0.20.1\n",
      "grpcio                       1.54.0\n",
      "h5py                         3.8.0\n",
      "huggingface-hub              0.14.1\n",
      "icecream                     2.1.3\n",
      "idna                         3.4\n",
      "ipykernel                    6.22.0\n",
      "ipython                      8.13.1\n",
      "ipython-genutils             0.2.0\n",
      "ipywidgets                   8.0.6\n",
      "isoduration                  20.11.0\n",
      "jax                          0.4.8\n",
      "jedi                         0.18.2\n",
      "Jinja2                       3.1.2\n",
      "joblib                       1.2.0\n",
      "jsonpointer                  2.3\n",
      "jsonschema                   4.17.3\n",
      "jupyter                      1.0.0\n",
      "jupyter_client               8.2.0\n",
      "jupyter-console              6.6.3\n",
      "jupyter_core                 5.3.0\n",
      "jupyter-events               0.6.3\n",
      "jupyter_server               2.5.0\n",
      "jupyter_server_terminals     0.4.4\n",
      "jupyterlab-pygments          0.2.2\n",
      "jupyterlab-widgets           3.0.7\n",
      "keras                        2.12.0\n",
      "kiwisolver                   1.4.4\n",
      "langcodes                    3.3.0\n",
      "libclang                     16.0.0\n",
      "Markdown                     3.4.3\n",
      "MarkupSafe                   2.1.2\n",
      "matplotlib                   3.7.1\n",
      "matplotlib-inline            0.1.6\n",
      "mistune                      2.0.5\n",
      "ml-dtypes                    0.1.0\n",
      "multidict                    6.0.4\n",
      "multiprocess                 0.70.14\n",
      "murmurhash                   1.0.9\n",
      "nbclassic                    0.5.6\n",
      "nbclient                     0.7.4\n",
      "nbconvert                    7.3.1\n",
      "nbformat                     5.8.0\n",
      "nest-asyncio                 1.5.6\n",
      "networkx                     3.1\n",
      "nltk                         3.8.1\n",
      "notebook                     6.5.4\n",
      "notebook_shim                0.2.3\n",
      "numpy                        1.23.5\n",
      "oauthlib                     3.2.2\n",
      "opt-einsum                   3.3.0\n",
      "packaging                    23.1\n",
      "pandas                       2.0.1\n",
      "pandocfilters                1.5.0\n",
      "parso                        0.8.3\n",
      "pathy                        0.10.1\n",
      "pickleshare                  0.7.5\n",
      "Pillow                       9.5.0\n",
      "pip                          23.0.1\n",
      "platformdirs                 3.5.0\n",
      "preshed                      3.0.8\n",
      "prometheus-client            0.16.0\n",
      "prompt-toolkit               3.0.38\n",
      "protobuf                     4.22.3\n",
      "psutil                       5.9.5\n",
      "pure-eval                    0.2.2\n",
      "pyahocorasick                2.0.0\n",
      "pyarrow                      12.0.0\n",
      "pyasn1                       0.5.0\n",
      "pyasn1-modules               0.3.0\n",
      "pycparser                    2.21\n",
      "pydantic                     1.10.7\n",
      "Pygments                     2.15.1\n",
      "pyparsing                    3.0.9\n",
      "pyrsistent                   0.19.3\n",
      "pytextrank                   3.2.4\n",
      "python-dateutil              2.8.2\n",
      "python-json-logger           2.0.7\n",
      "pytz                         2023.3\n",
      "pywin32                      306\n",
      "pywinpty                     2.0.10\n",
      "PyYAML                       6.0\n",
      "pyzmq                        25.0.2\n",
      "qtconsole                    5.4.2\n",
      "QtPy                         2.3.1\n",
      "regex                        2023.5.4\n",
      "requests                     2.29.0\n",
      "requests-oauthlib            1.3.1\n",
      "responses                    0.18.0\n",
      "rfc3339-validator            0.1.4\n",
      "rfc3986-validator            0.1.1\n",
      "rouge                        1.0.1\n",
      "rsa                          4.9\n",
      "scipy                        1.10.1\n",
      "seaborn                      0.12.2\n",
      "Send2Trash                   1.8.2\n",
      "setuptools                   67.7.2\n",
      "six                          1.16.0\n",
      "smart-open                   6.3.0\n",
      "sniffio                      1.3.0\n",
      "soupsieve                    2.4.1\n",
      "spacy                        3.5.2\n",
      "spacy-legacy                 3.0.12\n",
      "spacy-loggers                1.0.4\n",
      "srsly                        2.4.6\n",
      "stack-data                   0.6.2\n",
      "tensorboard                  2.12.3\n",
      "tensorboard-data-server      0.7.0\n",
      "tensorflow                   2.12.0\n",
      "tensorflow-estimator         2.12.0\n",
      "tensorflow-intel             2.12.0\n",
      "tensorflow-io-gcs-filesystem 0.31.0\n",
      "termcolor                    2.3.0\n",
      "terminado                    0.17.1\n",
      "textsearch                   0.0.24\n",
      "thinc                        8.1.9\n",
      "tinycss2                     1.2.1\n",
      "tokenizers                   0.13.3\n",
      "tornado                      6.3.1\n",
      "tqdm                         4.65.0\n",
      "traitlets                    5.9.0\n",
      "transformers                 4.28.1\n",
      "typer                        0.7.0\n",
      "typing_extensions            4.5.0\n",
      "tzdata                       2023.3\n",
      "uri-template                 1.2.0\n",
      "urllib3                      1.26.15\n",
      "wasabi                       1.1.1\n",
      "wcwidth                      0.2.6\n",
      "webcolors                    1.13\n",
      "webencodings                 0.5.1\n",
      "websocket-client             1.5.1\n",
      "Werkzeug                     2.3.3\n",
      "wheel                        0.40.0\n",
      "widgetsnbextension           4.0.7\n",
      "wrapt                        1.14.1\n",
      "xxhash                       3.2.0\n",
      "yarl                         1.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a0955ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate ROUGE score.\n",
    ":parameter    \n",
    "    :param y_test: string or list    \n",
    "    :param predicted: string or list\n",
    "'''\n",
    "def evaluate_summary(y_test, predicted):    \n",
    "    rouge_score = rouge.Rouge()\n",
    "    # join the elements of the lists with a space character\n",
    "    print(y_test)\n",
    "    print(predicted)\n",
    "    scores = rouge_score.get_scores(y_test, predicted, avg=True)       \n",
    "    score_1 = round(scores['rouge-1']['f'], 2)    \n",
    "    score_2 = round(scores['rouge-2']['f'], 2)    \n",
    "    score_L = round(scores['rouge-l']['f'], 2)    \n",
    "    print(\"rouge1:\", score_1, \"| rouge2:\", score_2, \"| rougeL:\",\n",
    "         score_2, \"--> avg rouge:\", round(np.mean(\n",
    "         [score_1,score_2,score_L]), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b797de50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parents beam with pride, can't stop from smiling from outpouring of support .\n",
      "Mom: \"I was so happy I didn't know what to do\"\n",
      "Burn center in U.S. has offered to provide treatment for reconstructive surgeries .\n",
      "Dad says, \"Anything for Youssif\"\n",
      "[('Youssif', 0.08991604280608116), ('burn victims', 0.07712531650502016), ('next Friday', 0.06321945993269831), ('Grossman Burn Center', 0.06265300861269642), ('victims', 0.059089448141081316), ('January day', 0.05883528589972477), ('Friday', 0.05709053619891388), ('Youssifs story', 0.056738529916598335), ('donations', 0.05573868660201247), ('support', 0.05540512809334803), ('people', 0.05451055206641087), ('Sherman Oaks', 0.05397623955921135), ('housing costs', 0.05076959110171379), ('Iraq', 0.050019070383050056), ('Youssifs cause', 0.04841783443181997), ('Youssifs case', 0.04725255342337501), ('Dr. Peter Grossman', 0.04544928150323525), ('CNN Iraqi staff', 0.04499074017723958), ('help', 0.04483858989149564), ('Peter Grossman', 0.04419040566287786), ('millions', 0.04417917689361844), ('many surgeries', 0.044125480405900336), ('masked men', 0.04406522285708443), ('January', 0.04279190162325774), ('new hope', 0.04169122200750232), ('California', 0.0408315898262241), ('CNN', 0.040774676419768036), ('executive director', 0.04033763300888381), ('the affiliated Grossman Burn Center', 0.04010131275707109), ('fire', 0.03952971830158126), ('Barbara Friedman', 0.039290506274598985), ('Atlanta', 0.03795288656069072), ('treatment', 0.03752004207510214), ('gasoline', 0.03699090653090757)]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Apply the function to predicted\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mevaluate_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtf_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[30], line 12\u001b[0m, in \u001b[0;36mevaluate_summary\u001b[1;34m(y_test, predicted)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_test)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(predicted)\n\u001b[1;32m---> 12\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mrouge_score\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m       \n\u001b[0;32m     13\u001b[0m score_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrouge-1\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m2\u001b[39m)    \n\u001b[0;32m     14\u001b[0m score_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrouge-2\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m2\u001b[39m)    \n",
      "File \u001b[1;32m~\\.virtualenvs\\text_summarization-RZoufpZG\\lib\\site-packages\\rouge\\rouge.py:108\u001b[0m, in \u001b[0;36mRouge.get_scores\u001b[1;34m(self, hyps, refs, avg, ignore_empty)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m avg:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_scores(hyps, refs)\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_avg_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\text_summarization-RZoufpZG\\lib\\site-packages\\rouge\\rouge.py:144\u001b[0m, in \u001b[0;36mRouge._get_avg_scores\u001b[1;34m(self, hyps, refs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (hyp, ref) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(hyps, refs):\n\u001b[0;32m    143\u001b[0m     hyp \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(_\u001b[38;5;241m.\u001b[39msplit()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m hyp\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 144\u001b[0m     ref \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(_\u001b[38;5;241m.\u001b[39msplit()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[43mref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics:\n\u001b[0;32m    147\u001b[0m         fn \u001b[38;5;241m=\u001b[39m Rouge\u001b[38;5;241m.\u001b[39mAVAILABLE_METRICS[m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "## Apply the function to predicted\n",
    "evaluate_summary(dtf_test[\"y\"][i], predicted[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50b52d7",
   "metadata": {},
   "source": [
    "### Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d02584fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Find the matching substrings in 2 strings.\n",
    ":parameter\n",
    "    :param a: string - raw text\n",
    "    :param b: string - raw text\n",
    ":return\n",
    "    2 lists used in to display matches\n",
    "'''\n",
    "def utils_split_sentences(a, b):\n",
    "    ## find clean matches\n",
    "    match = difflib.SequenceMatcher(isjunk=None, a=a, b=b, autojunk=True)\n",
    "    lst_match = [block for block in match.get_matching_blocks() if block.size > 20]\n",
    "    \n",
    "    ## difflib didn't find any match\n",
    "    if len(lst_match) == 0:\n",
    "        lst_a, lst_b = nltk.sent_tokenize(a), nltk.sent_tokenize(b)\n",
    "    \n",
    "    ## work with matches\n",
    "    else:\n",
    "        first_m, last_m = lst_match[0], lst_match[-1]\n",
    "\n",
    "        ### a\n",
    "        string = a[0 : first_m.a]\n",
    "        lst_a = [t for t in nltk.sent_tokenize(string)]\n",
    "        for n in range(len(lst_match)):\n",
    "            m = lst_match[n]\n",
    "            string = a[m.a : m.a+m.size]\n",
    "            lst_a.append(string)\n",
    "            if n+1 < len(lst_match):\n",
    "                next_m = lst_match[n+1]\n",
    "                string = a[m.a+m.size : next_m.a]\n",
    "                lst_a = lst_a + [t for t in nltk.sent_tokenize(string)]\n",
    "            else:\n",
    "                break\n",
    "        string = a[last_m.a+last_m.size :]\n",
    "        lst_a = lst_a + [t for t in nltk.sent_tokenize(string)]\n",
    "\n",
    "        ### b\n",
    "        string = b[0 : first_m.b]\n",
    "        lst_b = [t for t in nltk.sent_tokenize(string)]\n",
    "        for n in range(len(lst_match)):\n",
    "            m = lst_match[n]\n",
    "            string = b[m.b : m.b+m.size]\n",
    "            lst_b.append(string)\n",
    "            if n+1 < len(lst_match):\n",
    "                next_m = lst_match[n+1]\n",
    "                string = b[m.b+m.size : next_m.b]\n",
    "                lst_b = lst_b + [t for t in nltk.sent_tokenize(string)]\n",
    "            else:\n",
    "                break\n",
    "        string = b[last_m.b+last_m.size :]\n",
    "        lst_b = lst_b + [t for t in nltk.sent_tokenize(string)]\n",
    "    \n",
    "    return lst_a, lst_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "594e4ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Highlights the matched strings in text.\n",
    ":parameter\n",
    "    :param a: string - raw text\n",
    "    :param b: string - raw text\n",
    "    :param both: bool - search a in b and, if True, viceversa\n",
    "    :param sentences: bool - if False matches single words\n",
    ":return\n",
    "    text html, it can be visualized on notebook with display(HTML(text))\n",
    "'''\n",
    "def display_string_matching(a, b, both=True, sentences=True, titles=[]):\n",
    "    if sentences is True:\n",
    "        lst_a, lst_b = utils_split_sentences(a, b)\n",
    "    else:\n",
    "        lst_a, lst_b = a.split(), b.split()       \n",
    "    \n",
    "    ## highlight a\n",
    "    first_text = []\n",
    "    for i in lst_a:\n",
    "        if re.sub(r'[^\\w\\s]', '', i.lower()) in [re.sub(r'[^\\w\\s]', '', z.lower()) for z in lst_b]:\n",
    "            first_text.append('<span style=\"background-color:rgba(255,215,0,0.3);\">' + i + '</span>')\n",
    "        else:\n",
    "            first_text.append(i)\n",
    "    first_text = ' '.join(first_text)\n",
    "    \n",
    "    ## highlight b\n",
    "    second_text = []\n",
    "    if both is True:\n",
    "        for i in lst_b:\n",
    "            if re.sub(r'[^\\w\\s]', '', i.lower()) in [re.sub(r'[^\\w\\s]', '', z.lower()) for z in lst_a]:\n",
    "                second_text.append('<span style=\"background-color:rgba(255,215,0,0.3);\">' + i + '</span>')\n",
    "            else:\n",
    "                second_text.append(i)\n",
    "    else:\n",
    "        second_text.append(b) \n",
    "    second_text = ' '.join(second_text)\n",
    "    \n",
    "    ## concatenate\n",
    "    if len(titles) > 0:\n",
    "        first_text = \"<strong>\"+titles[0]+\"</strong><br>\"+first_text\n",
    "    if len(titles) > 1:\n",
    "        second_text = \"<strong>\"+titles[1]+\"</strong><br>\"+second_text\n",
    "    else:\n",
    "        second_text = \"---\"*65+\"<br><br>\"+second_text\n",
    "    final_text = first_text +'<br><br>'+ second_text\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f03814d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
