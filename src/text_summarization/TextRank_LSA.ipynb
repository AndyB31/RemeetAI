{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sumy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaDailz7u5uV",
        "outputId": "de9f2a39-08e1-4020-c82c-e81469a91da7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sumy\n",
            "  Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from sumy) (3.8.1)\n",
            "Collecting breadability>=0.1.20\n",
            "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycountry>=18.2.23\n",
            "  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting docopt<0.7,>=0.6.1\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from sumy) (2.27.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.0.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.9.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (4.65.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (2022.10.31)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pycountry>=18.2.23->sumy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2022.12.7)\n",
            "Building wheels for collected packages: breadability, docopt, pycountry\n",
            "  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21709 sha256=e68358e12c97a372fbb6ffdd6a264dc2bfe047d3e87c24f6f42cae7d4506e1af\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/22/90/b84fcc30e16598db20a0d41340616dbf9b1e82bbcc627b0b33\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13721 sha256=ac0b4045ec9c2bdd3ce7fbb62d6a060f4e7649313c4f36fb35ec8937a023d502\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for pycountry (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681847 sha256=b3b53c471ebc6cfcaadf54fc39c296b76d001c4011124d287dab92186e797b72\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/57/cc/290c5252ec97a6d78d36479a3c5e5ecc76318afcb241ad9dbe\n",
            "Successfully built breadability docopt pycountry\n",
            "Installing collected packages: docopt, pycountry, breadability, sumy\n",
            "Successfully installed breadability-0.1.20 docopt-0.6.2 pycountry-22.3.5 sumy-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytextrank"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXNpyR_7utYi",
        "outputId": "01eef040-277a-4e34-ad89-0974c2f9d6c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytextrank\n",
            "  Downloading pytextrank-3.2.4-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from pytextrank) (1.10.1)\n",
            "Collecting icecream>=2.1\n",
            "  Downloading icecream-2.1.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: graphviz>=0.13 in /usr/local/lib/python3.10/dist-packages (from pytextrank) (0.20.1)\n",
            "Requirement already satisfied: spacy>=3.0 in /usr/local/lib/python3.10/dist-packages (from pytextrank) (3.5.2)\n",
            "Requirement already satisfied: pygments>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from pytextrank) (2.14.0)\n",
            "Requirement already satisfied: networkx[default]>=2.6 in /usr/local/lib/python3.10/dist-packages (from pytextrank) (3.1)\n",
            "Collecting executing>=0.3.1\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting colorama>=0.3.9\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting asttokens>=2.0.1\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: matplotlib>=3.4 in /usr/local/lib/python3.10/dist-packages (from networkx[default]>=2.6->pytextrank) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from networkx[default]>=2.6->pytextrank) (1.22.4)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from networkx[default]>=2.6->pytextrank) (1.5.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (2.4.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (2.27.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (1.0.9)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (3.3.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (0.7.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (6.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (67.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (3.0.12)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (4.65.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (2.0.7)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (8.1.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (3.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (1.0.4)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (0.10.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (2.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (3.1.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (1.10.7)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (1.1.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0->pytextrank) (23.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.0.1->icecream>=2.1->pytextrank) (1.16.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->networkx[default]>=2.6->pytextrank) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->networkx[default]>=2.6->pytextrank) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->networkx[default]>=2.6->pytextrank) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->networkx[default]>=2.6->pytextrank) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->networkx[default]>=2.6->pytextrank) (4.39.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->networkx[default]>=2.6->pytextrank) (1.0.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->networkx[default]>=2.6->pytextrank) (8.4.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->networkx[default]>=2.6->pytextrank) (2022.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy>=3.0->pytextrank) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (1.26.15)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.0->pytextrank) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.0->pytextrank) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy>=3.0->pytextrank) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=3.0->pytextrank) (2.1.2)\n",
            "Installing collected packages: executing, colorama, asttokens, icecream, pytextrank\n",
            "Successfully installed asttokens-2.2.1 colorama-0.4.6 executing-1.2.0 icecream-2.1.3 pytextrank-3.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiA7vBj6r8RR"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import spacy\n",
        "import pytextrank\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "import nltk "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YE5dCYJwJVU",
        "outputId": "be877e25-1848-4078-9e2c-1e8525513f8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting path to the text file\n",
        "file_name = (\"./AWS - 1 (trimmed)2.txt\")\n",
        "\n",
        "# Loading the text file as a list of sentences\n",
        "with open(file_name, mode='rt', encoding='utf-8') as fp:\n",
        "    text = fp.read()"
      ],
      "metadata": {
        "id": "KeBPuVJxv6hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use LsaSummarizer from sumy library\n",
        "parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "summarizer_lsa = LsaSummarizer()\n",
        "summary_lsa = summarizer_lsa(parser.document, 9) # 2 sentences\n",
        "text_summary_lsa = \"\"\n",
        "for sentence in summary_lsa:\n",
        "    text_summary_lsa += str(sentence)\n",
        "print(\"Summary by LsaSummarizer:\")\n",
        "print(text_summary_lsa)\n",
        "\n",
        "# Opening the summary file in write mode\n",
        "with open('summary_lsa.txt', mode='w', encoding='utf-8') as fp:\n",
        "    # Write each string in the list to a separate line\n",
        "    for sentence in summary_lsa:\n",
        "        fp.write(str(sentence) + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iODt29kv8QL",
        "outputId": "455dc7bb-251e-488a-9c51-355044b060d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary by LsaSummarizer:\n",
            "fonction de besoin et par conséquent, ça permet aux clients d'optimiser leurs coûts.Voilà, c'est fini, peut-être on peut avoir 2 contrôles sur les 5 ans, quelque chose comme ça.Et en plus de ça, on va avoir des performances à la seconde de près, on ne veut pas avoir des performances, enfin préparer le chargement aujourd'hui pour l'an demain, ça ne nous convient pas en fait.On va prendre un cas simple, où les données, il n'y a pas de mise à jour après la journée.Et à partir de premier mois, ça va devenir une fois par an.Après, je souhaite qu'au bout d'un mois, tous mes données journalier, ils passent dans un notre bucket, ce bucket là, il appartient à une autre classe de disponibilité qui est beaucoup moins cher.Alors, c'est-à-dire, je ne dois pas développer quelque chose qui va me prendre mes données automatiquement pour les faire.Et je rappelle quand même, en fait, pour que vous voyez l'intérêt, pour avoir plus, pour mieux comprendre l'intérêt, en fait, le cours entre tous d'essayer donc une base de données et faire un schéma similaire, faire un choix similaire, il peut aller de quelques centaines ou quelques milliers d'euros à quelques millions d'euros.Bon, tous les clients n'ont pas une charge de plusieurs millions d'euros sur leur sourceur, mais, mais, enfin, personnellement, j'ai vu des, j'ai travaillé sur des projets où ce genre, enfin, c'est pas exactement cette architecture, là, c'est un exemple très simple.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use TextRank from pytextrank library\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.add_pipe(\"textrank\", last=True)\n",
        "doc = nlp(text)\n",
        "summary_textrank = doc._.textrank.summary(limit_phrases=15, limit_sentences=9) # 2 sentences\n",
        "print(\"Summary by TextRank:\")\n",
        "sentenced_summary_textrank = []\n",
        "for sentence in summary_textrank:\n",
        "    print(sentence)\n",
        "    sentenced_summary_textrank.append(str(sentence))\n",
        "\n",
        "# Open a new file in write mode\n",
        "with open(\"summary_txt_rank.txt\", \"w\") as file:\n",
        "    # Write each string in the list to a separate line\n",
        "    for sentence in sentenced_summary_textrank:\n",
        "        file.write(sentence + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agY4pZUrwevQ",
        "outputId": "e062e2d9-5919-46e6-8550-7f8a9fd42a25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary by TextRank:\n",
            "Oui, il suffit juste de rentrer des dates par exemple au début de la service.\n",
            "C'est quelque chose qui est pris en considération, c'est juste de la conf.\n",
            "C'est juste de la conf.\n",
            "Donc j'ai besoin, je peux dire, pour ma base, je peux avoir une base de données de 100 Giga seulement, qui va certainement coûter moins cher de plusieurs terrains, des centaines, même des terrains.\n",
            "Parce que voilà, on a, je ne sais pas, 100 Giga par jour, 100 Giga x 5 ans, il faut avoir une base de données qui contient 1 x 365 x 5 Giga.\n",
            "Et là, le coût sur la base de données, il se réduit juste à une journée, le coût sur le S3 première classe qui est plus cher que la deuxième classe, il sera sur un mois.\n",
            "Non, en fait, si je vous parle de ma, mon expérience concrète, on avait, si pas ici, une base de données relationnelle, on avait Elasticsearch et ici, c'était pas un seul mois, c'était, je pense, c'était trois mois.\n",
            "Alors je choisis une classe de disponibilité.\n",
            "Et à partir de premier mois, ça va devenir une fois par an.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentenced_summary_textrank)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghbYcXD9zBiN",
        "outputId": "6c474dfd-11d3-4d7f-d5f9-a4ca81330fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Oui, il suffit juste de rentrer des dates par exemple au début de la service.', \"C'est quelque chose qui est pris en considération, c'est juste de la conf.\", \"C'est juste de la conf.\", \"Donc j'ai besoin, je peux dire, pour ma base, je peux avoir une base de données de 100 Giga seulement, qui va certainement coûter moins cher de plusieurs terrains, des centaines, même des terrains.\", 'Parce que voilà, on a, je ne sais pas, 100 Giga par jour, 100 Giga x 5 ans, il faut avoir une base de données qui contient 1 x 365 x 5 Giga.', 'Et là, le coût sur la base de données, il se réduit juste à une journée, le coût sur le S3 première classe qui est plus cher que la deuxième classe, il sera sur un mois.', \"Non, en fait, si je vous parle de ma, mon expérience concrète, on avait, si pas ici, une base de données relationnelle, on avait Elasticsearch et ici, c'était pas un seul mois, c'était, je pense, c'était trois mois.\", 'Alors je choisis une classe de disponibilité.', 'Et à partir de premier mois, ça va devenir une fois par an.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uTH7busHyTab"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}