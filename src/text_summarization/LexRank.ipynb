{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "history_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://iq.opengenus.org/lexrank-text-summarization/"
      ],
      "metadata": {
        "id": "UprwF69Whdzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lexrank"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46OuFfWWgQuf",
        "outputId": "89dbd7c9-6946-472b-efa4-616eed29af5d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lexrank\n",
            "  Downloading lexrank-0.1.0-py3-none-any.whl (69 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/69.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urlextract>=0.7\n",
            "  Downloading urlextract-1.8.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from lexrank) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from lexrank) (1.22.4)\n",
            "Requirement already satisfied: regex>=2017.11.9 in /usr/local/lib/python3.10/dist-packages (from lexrank) (2022.10.31)\n",
            "Collecting path.py>=10.5\n",
            "  Downloading path.py-12.5.0-py3-none-any.whl (2.3 kB)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from lexrank) (1.10.1)\n",
            "Collecting path\n",
            "  Downloading path-16.6.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from urlextract>=0.7->lexrank) (3.12.0)\n",
            "Collecting uritools\n",
            "  Downloading uritools-4.0.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from urlextract>=0.7->lexrank) (3.3.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from urlextract>=0.7->lexrank) (3.4)\n",
            "Installing collected packages: uritools, path, urlextract, path.py, lexrank\n",
            "Successfully installed lexrank-0.1.0 path-16.6.0 path.py-12.5.0 uritools-4.0.1 urlextract-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lUYmgleLffMX"
      },
      "outputs": [],
      "source": [
        "# Importing the required packages\n",
        "from lexrank import STOPWORDS, LexRank"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting path to the text file\n",
        "file_name = (\"./AWS - 1 (trimmed)2.txt\")\n",
        "\n",
        "# Loading the text file as a list of sentences\n",
        "with open(file_name, mode='rt', encoding='utf-8') as fp:\n",
        "    text = fp.read()\n",
        "\n",
        "# Creating a LexRank instance\n",
        "lxr = LexRank([text], stopwords=STOPWORDS['fr'])\n",
        "\n",
        "# Splitting the text by space\n",
        "words = text.split()\n",
        "\n",
        "# Computing the number of words\n",
        "num_words = len(words)\n",
        "\n",
        "# Splitting the text by \".\"\n",
        "sentences = text.split(\".\")\n",
        "\n",
        "# Computing the number of sentences\n",
        "num_sentences = len(sentences)\n",
        "\n",
        "# Calculating the average sentence length in words\n",
        "average_length = num_words / num_sentences\n",
        "\n",
        "print(average_length)\n",
        "\n",
        "user_summary_size_sentence = 9 #user input parameter\n",
        "\n",
        "# Setting the desired summary size in words\n",
        "summary_size_words = average_length * user_summary_size_sentence \n",
        "\n",
        "# Estimating the summary size in sentences\n",
        "summary_size_sentences = int(summary_size_words / average_length)\n",
        "\n",
        "# Summarizing the text with summary_size_sentences total\n",
        "summary = lxr.get_summary(sentences, summary_size=summary_size_sentences)\n",
        "\n",
        "# Printing the summary\n",
        "print('\\n'.join(summary))\n",
        "\n",
        "# Opening the summary file in write mode\n",
        "with open('summary.txt', mode='wt', encoding='utf-8') as fp:\n",
        "    # Writing the summary to the file\n",
        "    fp.write('\\n'.join(summary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuHiKIK7gPMO",
        "outputId": "44644cdd-a741-4c1b-9f89-aab153b3f531"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17.070422535211268\n",
            " Donc là vraiment ça en termes de disponibilité, c'est pas énorme en fait, c'est pas loin d'être les données qui sont requettées tous les jours par exemple\n",
            " Donc nos données doivent être conservées 5 ans avec la possibilité d'avoir d'être consulter une ou deux fois sur l'année et pour la disponibilité, on n'a pas besoin de l'avoir le jour même, on a besoin de les avoir peut-être pour le long de l'an\n",
            " On va faire un audit demain et voilà, ils vont consulter ces données et le contrôle, ils prennent par exemple 3 jours et c'est fini\n",
            " Et là, le coût sur la base de données, il se réduit juste à une journée, le coût sur le S3 première classe qui est plus cher que la deuxième classe, il sera sur un mois\n",
            " Alors si au même temps je dis pour S3, je dis mais non, moi j'ai encore d'autres données qui sont quand même requettables tous les jours\n",
            " Alors, c'est-à-dire, je ne dois pas développer quelque chose qui va me prendre mes données automatiquement pour les faire\n",
            " D'accord ? Alors premier jour, nos données arrivent en base\n",
            " On a des données par exemple, on les garde pour des fins légaux, c'est-à-dire quoi ? C'est-à-dire on a une contrainte légale, on doit garder les données pendant 5 ans\n",
            " Alors donc, si on garde tous nos données pendant les cinq ans sur la base donnée, ça va coûter très très cher\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(lxr.get_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo-Zsb2hiqKv",
        "outputId": "acdbb36c-daca-4652-b70b-e01ddc9c516e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on method get_summary in module lexrank.algorithms.summarizer:\n",
            "\n",
            "get_summary(sentences, summary_size=1, threshold=0.03, fast_power_method=True) method of lexrank.algorithms.summarizer.LexRank instance\n",
            "\n"
          ]
        }
      ]
    }
  ]
}